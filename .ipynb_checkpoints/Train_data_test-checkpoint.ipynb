{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "import pickle\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.externals import joblib \n",
    "from sklearn.metrics import f1_score, roc_auc_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numeric_features = ['word_count','title_word_count','noun_count','verb_count','adj_count',\n",
    "                    'adv_count','pron_count','genre_direct','genre_news','genre_social']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(database_filepath):\n",
    "    # load from database\n",
    "    engine = sqlalchemy.create_engine('sqlite:///{}'.format(database_filepath))\n",
    "    df = pd.read_sql_table('InsertTableName', engine)\n",
    "    \n",
    "    # split input and response variables\n",
    "    X = df[['message'] + numeric_features]\n",
    "    #X = df['message']\n",
    "    Y = df.drop(['id','message','original','genre'] + numeric_features, axis=1)\n",
    "    category_names = Y.columns\n",
    "    return X, Y, category_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # lemmatize and remove stop words\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    clean_tokens = [tok.lower().strip() for tok in tokens]\n",
    "\n",
    "    return clean_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    # Scale engineered features separate to Natural Language functions\n",
    "    # We create the preprocessing pipelines for both numeric and text data.\n",
    "    \n",
    "    text_transformer = Pipeline([\n",
    "                ('vect', CountVectorizer(tokenizer=tokenize, \n",
    "                                         ngram_range=(1, 2), \n",
    "                                         max_features=5000, \n",
    "                                         max_df=0.5,\n",
    "                                        )),\n",
    "                ('tfidf', TfidfTransformer(use_idf= True))\n",
    "            ])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "                    transformers=[\n",
    "                        ('num', StandardScaler(), numeric_features),\n",
    "                        ('txt', text_transformer, 'message')\n",
    "                        ])\n",
    "\n",
    "    # Append classifier to preprocessing pipeline.\n",
    "    # Now we have a full prediction pipeline.\n",
    "    pipeline_model = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        #('clf', MultiOutputClassifier(LinearSVC(C=1.0, multi_class='crammer_singer', dual=False, random_state=42,max_iter = 10000)))\n",
    "        ('clf', MultiOutputClassifier(RandomForestClassifier(min_samples_split=8, n_estimators=100, random_state=42)))\n",
    "        ])\n",
    "\n",
    "    return pipeline_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, Y_test):\n",
    "    # Note: this function used to have a variable \"category_names\" per the default\n",
    "    # I'm not sure it was necessary so I have removed it.\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    for index, column in enumerate(Y_test.columns):\n",
    "        print(column)\n",
    "        print('f1 score: {}'.format(f1_score(Y_test[column].values, y_pred[:,index], average='weighted')))\n",
    "        print('AUC score: {}'.format(roc_auc_score(Y_test[column].values, y_pred[:,index], average='weighted')))\n",
    "        print('Class report: {}'.format(classification_report(Y_test[column].values, y_pred[:,index])))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_filepath):\n",
    "    joblib.dump(model, model_filepath) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(database_filepath, model_filepath):\n",
    "    print('Loading data...\\n    DATABASE: {}'.format(database_filepath))\n",
    "    X, Y, category_names = load_data(database_filepath)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "    print('Building model...')\n",
    "    model = build_model()\n",
    "\n",
    "    print('Training model...')\n",
    "    #print(X_train.head())\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    print('Evaluating model...')\n",
    "    evaluate_model(model, X_test, Y_test)\n",
    "    # Note: used to also include parameter category_names\n",
    "\n",
    "    print('Saving model...\\n    MODEL: {}'.format(model_filepath))\n",
    "    save_model(model, model_filepath)\n",
    "\n",
    "    print('Trained model saved!')\n",
    "\n",
    "def failstmt():\n",
    "        print('Please provide the filepath of the disaster messages database '\\\n",
    "              'as the first argument and the filepath of the pickle file to '\\\n",
    "              'save the model to as the second argument. \\n\\nExample: python '\\\n",
    "              'train_classifier.py /data/DisasterResponse.db classifier.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "    DATABASE: data/DisasterResponse.db\n",
      "Building model...\n",
      "Training model...\n",
      "                                                 message  word_count  \\\n",
      "6618    Good morning! I would like to congratulate you.            8   \n",
      "23819  KRCS plans to support those who have been affe...          37   \n",
      "21840  At Mahadampa School, children crowd round the ...          26   \n",
      "20100  The long-term plan will focus on groundwater e...          29   \n",
      "23707  A long-running separatist rebellion had thinne...          11   \n",
      "\n",
      "       title_word_count  noun_count  verb_count  adj_count  adv_count  \\\n",
      "6618                  2           0           0          0          0   \n",
      "23819                 0           0           0          0          0   \n",
      "21840                 3           0           0          0          0   \n",
      "20100                 3           0           0          0          0   \n",
      "23707                 1           0           0          0          0   \n",
      "\n",
      "       pron_count  \n",
      "6618            0  \n",
      "23819           0  \n",
      "21840           0  \n",
      "20100           0  \n",
      "23707           0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:605: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  res = transformer.transform(X)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "multiclass-multioutput is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-d609f7e74eba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/DisasterResponse.db'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'models/model.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-50-f2676a15b890>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(database_filepath, model_filepath)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Evaluating model...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mevaluate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[1;31m# Note: used to also include parameter category_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-291af083177c>\u001b[0m in \u001b[0;36mevaluate_model\u001b[1;34m(model, X_test, Y_test)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'f1 score: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'weighted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'AUC score: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'weighted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[0;32m    718\u001b[0m     return fbeta_score(y_true, y_pred, 1, labels=labels,\n\u001b[0;32m    719\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 720\u001b[1;33m                        sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[0;32m    832\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    833\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'f-score'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 834\u001b[1;33m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    835\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    836\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[0;32m   1029\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1031\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1032\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;31m# No metrics support \"multiclass-multioutput\" format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multilabel-indicator\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0} is not supported\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: multiclass-multioutput is not supported"
     ]
    }
   ],
   "source": [
    "main('data/DisasterResponse.db', 'models/model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "    DATABASE: data/DisasterResponse.db\n",
      "Building model...\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:605: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  res = transformer.transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6628122832128838\n",
      "f1 score: 0.7875380604683766\n",
      "AUC score: 0.6628122832128838\n",
      "Class report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.37      0.49      1299\n",
      "           1       0.82      0.96      0.88      3945\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      5244\n",
      "   macro avg       0.78      0.66      0.69      5244\n",
      "weighted avg       0.80      0.81      0.79      5244\n",
      "\n",
      "0.7639821681526541\n",
      "f1 score: 0.8956037339363213\n",
      "AUC score: 0.7639821681526541\n",
      "Class report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94      4364\n",
      "           1       0.81      0.55      0.66       880\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      5244\n",
      "   macro avg       0.86      0.76      0.80      5244\n",
      "weighted avg       0.90      0.90      0.90      5244\n",
      "\n",
      "0.5\n",
      "f1 score: 0.9939971522135932\n",
      "AUC score: 0.5\n",
      "Class report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5223\n",
      "           1       0.00      0.00      0.00        21\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      5244\n",
      "   macro avg       0.50      0.50      0.50      5244\n",
      "weighted avg       0.99      1.00      0.99      5244\n",
      "\n",
      "0.7750764393442742\n",
      "f1 score: 0.7839222764540011\n",
      "AUC score: 0.7750764393442742\n",
      "Class report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      3102\n",
      "           1       0.74      0.72      0.73      2142\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      5244\n",
      "   macro avg       0.78      0.78      0.78      5244\n",
      "weighted avg       0.78      0.78      0.78      5244\n",
      "\n",
      "0.5654351352765713\n",
      "f1 score: 0.9076564056505269\n",
      "AUC score: 0.5654351352765713\n",
      "Class report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      4850\n",
      "           1       0.64      0.14      0.23       394\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      5244\n",
      "   macro avg       0.79      0.57      0.59      5244\n",
      "weighted avg       0.91      0.93      0.91      5244\n",
      "\n",
      "0.5929622950819671\n",
      "f1 score: 0.9478455581729618\n",
      "AUC score: 0.5929622950819671\n",
      "Class report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      5000\n",
      "           1       0.78      0.19      0.30       244\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      5244\n",
      "   macro avg       0.87      0.59      0.64      5244\n",
      "weighted avg       0.95      0.96      0.95      5244\n",
      "\n",
      "0.5467069269836546\n",
      "f1 score: 0.9629137293336418\n",
      "AUC score: 0.5467069269836546\n",
      "Class report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      5099\n",
      "           1       0.47      0.10      0.16       145\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      5244\n",
      "   macro avg       0.72      0.55      0.57      5244\n",
      "weighted avg       0.96      0.97      0.96      5244\n",
      "\n",
      "0.4999029126213592\n",
      "f1 score: 0.9730978348024102\n",
      "AUC score: 0.4999029126213592\n",
      "Class report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5150\n",
      "           1       0.00      0.00      0.00        94\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      5244\n",
      "   macro avg       0.49      0.50      0.50      5244\n",
      "weighted avg       0.96      0.98      0.97      5244\n",
      "\n",
      "0.5673109157957643\n",
      "f1 score: 0.9625220600032086\n",
      "AUC score: 0.5673109157957643\n",
      "Class report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      5082\n",
      "           1       0.79      0.14      0.23       162\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      5244\n",
      "   macro avg       0.88      0.57      0.61      5244\n",
      "weighted avg       0.97      0.97      0.96      5244\n",
      "\n",
      "0.8007767041071171\n",
      "f1 score: 0.964614332490044\n",
      "AUC score: 0.8007767041071171\n",
      "Class report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      4934\n",
      "           1       0.77      0.61      0.68       310\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      5244\n",
      "   macro avg       0.87      0.80      0.83      5244\n",
      "weighted avg       0.96      0.97      0.96      5244\n",
      "\n",
      "0.8629989430158905\n",
      "f1 score: 0.9516055287906897\n",
      "AUC score: 0.8629989430158905\n",
      "Class report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      4671\n",
      "           1       0.80      0.75      0.77       573\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      5244\n",
      "   macro avg       0.89      0.86      0.87      5244\n",
      "weighted avg       0.95      0.95      0.95      5244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.7510873131879604\n",
      "f1 score: 0.94143679434714\n",
      "AUC score: 0.7510873131879604\n",
      "Class report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      4789\n",
      "           1       0.80      0.51      0.63       455\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      5244\n",
      "   macro avg       0.88      0.75      0.80      5244\n",
      "weighted avg       0.94      0.95      0.94      5244\n",
      "\n",
      "0.6910494654397094\n",
      "f1 score: 0.9867049307620095\n",
      "AUC score: 0.6910494654397094\n",
      "Class report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5166\n",
      "           1       0.70      0.38      0.50        78\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      5244\n",
      "   macro avg       0.84      0.69      0.74      5244\n",
      "weighted avg       0.99      0.99      0.99      5244\n",
      "\n",
      "0.5302398128290116\n",
      "f1 score: 0.9701652164549394\n",
      "AUC score: 0.5302398128290116\n",
      "Class report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5129\n",
      "           1       0.78      0.06      0.11       115\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      5244\n",
      "   macro avg       0.88      0.53      0.55      5244\n",
      "weighted avg       0.97      0.98      0.97      5244\n",
      "\n",
      "0.5087719298245614\n",
      "f1 score: 0.9841944799412375\n",
      "AUC score: 0.5087719298245614\n",
      "Class report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5187\n",
      "           1       1.00      0.02      0.03        57\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      5244\n",
      "   macro avg       0.99      0.51      0.51      5244\n",
      "weighted avg       0.99      0.99      0.98      5244\n",
      "\n",
      "0.561614812341144\n",
      "f1 score: 0.9616809820614167\n",
      "AUC score: 0.561614812341144\n",
      "Class report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      5085\n",
      "           1       0.61      0.13      0.21       159\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      5244\n",
      "   macro avg       0.79      0.56      0.60      5244\n",
      "weighted avg       0.96      0.97      0.96      5244\n",
      "\n",
      "0.696338105533531\n",
      "f1 score: 0.9607427577736343\n",
      "AUC score: 0.696338105533531\n",
      "Class report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      4987\n",
      "           1       0.83      0.40      0.54       257\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      5244\n",
      "   macro avg       0.90      0.70      0.76      5244\n",
      "weighted avg       0.96      0.97      0.96      5244\n",
      "\n",
      "0.5292135792076602\n",
      "f1 score: 0.8299611447028956\n",
      "AUC score: 0.5292135792076602\n",
      "Class report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93      4580\n",
      "           1       0.60      0.06      0.12       664\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      5244\n",
      "   macro avg       0.74      0.53      0.53      5244\n",
      "weighted avg       0.84      0.88      0.83      5244\n",
      "\n",
      "0.4998983946352367\n",
      "f1 score: 0.9084920349742484\n",
      "AUC score: 0.4998983946352367\n",
      "Class report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      4921\n",
      "           1       0.00      0.00      0.00       323\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      5244\n",
      "   macro avg       0.47      0.50      0.48      5244\n",
      "weighted avg       0.88      0.94      0.91      5244\n",
      "\n",
      "0.5733958134249335\n",
      "f1 score: 0.9436438806338707\n",
      "AUC score: 0.5733958134249335\n",
      "Class report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      4996\n",
      "           1       0.76      0.15      0.25       248\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      5244\n",
      "   macro avg       0.86      0.57      0.61      5244\n",
      "weighted avg       0.95      0.96      0.94      5244\n",
      "\n",
      "0.5944334281690951\n",
      "f1 score: 0.9428228234318503\n",
      "AUC score: 0.5944334281690951\n",
      "Class report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      4971\n",
      "           1       0.87      0.19      0.31       273\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      5244\n",
      "   macro avg       0.91      0.59      0.64      5244\n",
      "weighted avg       0.95      0.96      0.94      5244\n",
      "\n",
      "0.538364262196947\n",
      "f1 score: 0.9738119298440802\n",
      "AUC score: 0.538364262196947\n",
      "Class report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5140\n",
      "           1       0.89      0.08      0.14       104\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      5244\n",
      "   macro avg       0.94      0.54      0.57      5244\n",
      "weighted avg       0.98      0.98      0.97      5244\n",
      "\n",
      "0.5\n",
      "f1 score: 0.9928546657419742\n",
      "AUC score: 0.5\n",
      "Class report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5219\n",
      "           1       0.00      0.00      0.00        25\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      5244\n",
      "   macro avg       0.50      0.50      0.50      5244\n",
      "weighted avg       0.99      1.00      0.99      5244\n",
      "\n",
      "0.5\n",
      "f1 score: 0.9851505628436916\n",
      "AUC score: 0.5\n",
      "Class report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      5192\n",
      "           1       0.00      0.00      0.00        52\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      5244\n",
      "   macro avg       0.50      0.50      0.50      5244\n",
      "weighted avg       0.98      0.99      0.99      5244\n",
      "\n",
      "0.5\n",
      "f1 score: 0.9931402599038481\n",
      "AUC score: 0.5\n",
      "Class report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5220\n",
      "           1       0.00      0.00      0.00        24\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      5244\n",
      "   macro avg       0.50      0.50      0.50      5244\n",
      "weighted avg       0.99      1.00      0.99      5244\n",
      "\n",
      "0.5\n",
      "f1 score: 0.9862910649938189\n",
      "AUC score: 0.5\n",
      "Class report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      5196\n",
      "           1       0.00      0.00      0.00        48\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      5244\n",
      "   macro avg       0.50      0.50      0.50      5244\n",
      "weighted avg       0.98      0.99      0.99      5244\n",
      "\n",
      "0.49990045789368903\n",
      "f1 score: 0.9371431590181716\n",
      "AUC score: 0.49990045789368903\n",
      "Class report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      5023\n",
      "           1       0.00      0.00      0.00       221\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      5244\n",
      "   macro avg       0.48      0.50      0.49      5244\n",
      "weighted avg       0.92      0.96      0.94      5244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.849852092647644\n",
      "f1 score: 0.8893908220839805\n",
      "AUC score: 0.849852092647644\n",
      "Class report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93      3808\n",
      "           1       0.83      0.76      0.79      1436\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      5244\n",
      "   macro avg       0.87      0.85      0.86      5244\n",
      "weighted avg       0.89      0.89      0.89      5244\n",
      "\n",
      "0.7359619398328885\n",
      "f1 score: 0.9447324659236892\n",
      "AUC score: 0.7359619398328885\n",
      "Class report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      4801\n",
      "           1       0.91      0.48      0.63       443\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      5244\n",
      "   macro avg       0.93      0.74      0.80      5244\n",
      "weighted avg       0.95      0.95      0.94      5244\n",
      "\n",
      "0.8206134231837259\n",
      "f1 score: 0.9456789243727683\n",
      "AUC score: 0.8206134231837259\n",
      "Class report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      4723\n",
      "           1       0.78      0.66      0.72       521\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      5244\n",
      "   macro avg       0.87      0.82      0.84      5244\n",
      "weighted avg       0.94      0.95      0.95      5244\n",
      "\n",
      "0.5714285714285714\n",
      "f1 score: 0.9874352620514882\n",
      "AUC score: 0.5714285714285714\n",
      "Class report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      5188\n",
      "           1       1.00      0.14      0.25        56\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      5244\n",
      "   macro avg       1.00      0.57      0.62      5244\n",
      "weighted avg       0.99      0.99      0.99      5244\n",
      "\n",
      "0.8930810735026408\n",
      "f1 score: 0.9705932577149626\n",
      "AUC score: 0.8930810735026408\n",
      "Class report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      4765\n",
      "           1       0.88      0.80      0.83       479\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      5244\n",
      "   macro avg       0.93      0.89      0.91      5244\n",
      "weighted avg       0.97      0.97      0.97      5244\n",
      "\n",
      "0.5949877786612481\n",
      "f1 score: 0.9782026466540912\n",
      "AUC score: 0.5949877786612481\n",
      "Class report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5145\n",
      "           1       0.66      0.19      0.30        99\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      5244\n",
      "   macro avg       0.82      0.59      0.64      5244\n",
      "weighted avg       0.98      0.98      0.98      5244\n",
      "\n",
      "0.5209764585862239\n",
      "f1 score: 0.9333284888001385\n",
      "AUC score: 0.5209764585862239\n",
      "Class report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      4996\n",
      "           1       0.48      0.04      0.08       248\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      5244\n",
      "   macro avg       0.72      0.52      0.53      5244\n",
      "weighted avg       0.93      0.95      0.93      5244\n",
      "\n",
      "0.7082228558222078\n",
      "f1 score: 0.8576557028663165\n",
      "AUC score: 0.7082228558222078\n",
      "Class report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92      4265\n",
      "           1       0.77      0.45      0.57       979\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      5244\n",
      "   macro avg       0.83      0.71      0.75      5244\n",
      "weighted avg       0.86      0.87      0.86      5244\n",
      "\n",
      "Saving model...\n",
      "    MODEL: models/model.pkl\n",
      "Trained model saved!\n"
     ]
    }
   ],
   "source": [
    "database_filepath = 'data/DisasterResponse.db'\n",
    "model_filepath = 'models/model.pkl'\n",
    "\n",
    "print('Loading data...\\n    DATABASE: {}'.format(database_filepath))\n",
    "X, Y, category_names = load_data(database_filepath)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "#print(category_names)\n",
    "\n",
    "print('Building model...')\n",
    "model = build_model()\n",
    "\n",
    "print('Training model...')\n",
    "#print(X_train.head())\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "print('Evaluating model...')\n",
    "evaluate_model(model, X_test, Y_test)\n",
    "# Note: used to also include parameter category_names\n",
    "\n",
    "print('Saving model...\\n    MODEL: {}'.format(model_filepath))\n",
    "save_model(model, model_filepath)\n",
    "\n",
    "print('Trained model saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:605: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  res = transformer.transform(X)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5236, 10)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5236, 10)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genre_direct\n",
      "0.9429103662331009\n",
      "genre_news\n",
      "0.9531169295040262\n",
      "genre_social\n",
      "0.953631261691956\n",
      "word_count\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "multiclass format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-b09974fc2959>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr)\u001b[0m\n\u001b[0;32m    354\u001b[0m     return _average_binary_score(\n\u001b[0;32m    355\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m         sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0my_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multilabel-indicator\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0} format is not supported\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: multiclass format is not supported"
     ]
    }
   ],
   "source": [
    "for index, column in enumerate(Y_test.columns):\n",
    "    print(column)\n",
    "    print(roc_auc_score(Y_test[column].values, y_pred[:,index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['genre_direct', 'genre_news', 'genre_social', 'word_count',\n",
       "       'title_word_count', 'noun_count', 'verb_count', 'adj_count',\n",
       "       'adv_count', 'pron_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
