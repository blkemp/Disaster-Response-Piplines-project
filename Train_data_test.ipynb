{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(['punkt', 'wordnet', 'averaged_perceptron_tagger', 'stopwords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import pickle\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.externals import joblib \n",
    "from sklearn.metrics import f1_score, classification_report, make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class BasicTextAnalytics(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    Class for returning some basic numerical data for text analysis to include in \n",
    "    modelling. Such as: \n",
    "    - Number of sentences\n",
    "    - Number of words\n",
    "    - Number of nouns\n",
    "    - Number of verbs\n",
    "    - Number of adjectives\n",
    "    A lot of the above were taken from ideas found here: \n",
    "    https://www.analyticsvidhya.com/blog/2018/04/a-comprehensive-guide-to-understand-and-implement-text-classification-in-python/\n",
    "    '''\n",
    "    pos_family = {\n",
    "    'noun' : ['NN','NNS','NNP','NNPS'],\n",
    "    'pron' : ['PRP','PRP$','WP','WP$'],\n",
    "    'verb' : ['VB','VBD','VBG','VBN','VBP','VBZ'],\n",
    "    'adj' :  ['JJ','JJR','JJS'],\n",
    "    'adv' : ['RB','RBR','RBS','WRB']\n",
    "    }\n",
    "\n",
    "    # function to check and get the part of speech tag count of a words in a given sentence\n",
    "    def check_pos_tag(self, text, flag):\n",
    "        '''\n",
    "        Returns the count of a given NL pos_tag, based on user selection. E.g. number of nouns.\n",
    "        INPUTS\n",
    "        text - the given text to analyse\n",
    "        flag - pos family to analyse, one of 'noun', 'pron' , 'verb', 'adj' or 'adv'\n",
    "        '''\n",
    "        count = 0\n",
    "        try:\n",
    "            wiki = textblob.TextBlob(text)\n",
    "            for tup in wiki.tags:\n",
    "                ppo = list(tup)[1]\n",
    "                if ppo in pos_family[flag]:\n",
    "                    count += 1\n",
    "        except:\n",
    "            pass\n",
    "        return count\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        trainDF = pd.DataFrame()\n",
    "        trainDF['text'] = X\n",
    "        trainDF['word_count'] = trainDF['text'].apply(lambda x: len(x.split()))\n",
    "        trainDF['title_word_count'] = trainDF['text'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
    "        trainDF['noun_count'] = trainDF['text'].apply(lambda x: self.check_pos_tag(x, 'noun'))\n",
    "        trainDF['verb_count'] = trainDF['text'].apply(lambda x: self.check_pos_tag(x, 'verb'))\n",
    "        trainDF['adj_count'] = trainDF['text'].apply(lambda x: self.check_pos_tag(x, 'adj'))\n",
    "        trainDF['adv_count'] = trainDF['text'].apply(lambda x: self.check_pos_tag(x, 'adv'))\n",
    "        trainDF['pron_count'] = trainDF['text'].apply(lambda x: self.check_pos_tag(x, 'pron'))\n",
    "        \n",
    "        return trainDF.drop('text',axis=1)\n",
    "\n",
    "def load_data(database_filepath):\n",
    "    '''Imports the \"InsertTableName\" table from a specified database file\n",
    "    Returns X and Y datasets as pandas DataFrames as well as a list of column names\n",
    "    (column names not currently in use but may be useful for later analyses of \n",
    "    feature importance, etc.)'''\n",
    "    #  load from database\n",
    "    engine = create_engine('sqlite:///{}'.format(database_filepath))\n",
    "    df = pd.read_sql_table('InsertTableName', engine)\n",
    "\n",
    "    # split input and response variables\n",
    "    category_names = set(df.columns) - set({'id',\n",
    "                                            'message',\n",
    "                                            'original',\n",
    "                                            'related',\n",
    "                                            'genre',\n",
    "                                            'genre_direct',\n",
    "                                            'genre_news',\n",
    "                                            'genre_social'})\n",
    "    category_names = list(category_names)\n",
    "    print(category_names)\n",
    "    X = df['message']\n",
    "    Y = df[category_names]\n",
    "    return X, Y, category_names\n",
    "\n",
    "def tokenize(text):\n",
    "    '''tokenizing function which splits given text into words, removing stop words and spaces \n",
    "    as well as outputting in lower case'''\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # lemmatize and remove stop words\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    clean_tokens = [tok.lower().strip() for tok in tokens]\n",
    "\n",
    "    return clean_tokens\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    ''' Build and scale engineered features separate to Natural Language transformations\n",
    "    Creates preprocessing pipelines for both numeric and text data, then completes a quick\n",
    "    Grid search over RandomForestClassifier key parameters.\n",
    "    Note: gridsearch has not been applied to text transformation hyperparameters based on previous\n",
    "    searches showing minimal impacts in tuning these. \n",
    "    '''\n",
    "    pipeline_model = Pipeline([\n",
    "        ('features', FeatureUnion([\n",
    "            ('text_pipeline', Pipeline([\n",
    "                ('vect', CountVectorizer(tokenizer=tokenize, \n",
    "                                        ngram_range=(1, 2),\n",
    "                                        max_features=5000,\n",
    "                                        max_df=0.5)),\n",
    "                ('tfidf', TfidfTransformer())\n",
    "            ])),\n",
    "\n",
    "            ('numerical_pipeline', Pipeline([\n",
    "                ('analytics', BasicTextAnalytics()),\n",
    "                ('norm', StandardScaler())\n",
    "                ]))\n",
    "        ])),\n",
    "\n",
    "        ('clf', MultiOutputClassifier(RandomForestClassifier(n_estimators=100, random_state=42, max_depth=100)))\n",
    "    ])\n",
    "    # specify parameters for grid search\n",
    "    parameters = {\n",
    "        'clf__estimator__min_samples_split' : [8,16],\n",
    "    }\n",
    "\n",
    "    # create grid search object\n",
    "    # using f1 score rather than auc because of the significant imbalance in class distributions\n",
    "    # per https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/\n",
    "    scorer = make_scorer(f1_score, average = 'weighted')\n",
    "    cv = GridSearchCV(pipeline_model, parameters, scoring = scorer, verbose=3)\n",
    "\n",
    "    return cv\n",
    "\n",
    "def evaluate_model(model, X_test, Y_test):\n",
    "    '''\n",
    "    Evalutes the model using sklearns 'classification report' function to return precision and recall for each class\n",
    "    Inputs: model - model or pipeline contructed through sklearn (or other ML tool with a \n",
    "                        \"predict\" function avaialable for the object type)\n",
    "            X_test - test set data [pandas dataframe/series]\n",
    "            Y_test - correct categories for the test data [pandas dataframe/series]\n",
    "    '''\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    for index, feature in enumerate(Y_test.columns):\n",
    "        print(feature)\n",
    "        print(classification_report(Y_test[feature], y_pred[:, index]))\n",
    "        print('f1 score: {}'.format(f1_score(Y_test[feature], y_pred[:, index], average='weighted')))\n",
    "    \n",
    "    pass\n",
    "\n",
    "\n",
    "def save_model(model, model_filepath):\n",
    "    '''\n",
    "    Saves the model trained within the \"main\" function.\n",
    "    '''\n",
    "    pickle.dump(model, open(model_filepath, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "    DATABASE: data/DisasterResponse.db\n",
      "['buildings', 'other_weather', 'search_and_rescue', 'floods', 'clothing', 'hospitals', 'water', 'food', 'shops', 'medical_help', 'aid_centers', 'storm', 'direct_report', 'offer', 'military', 'electricity', 'aid_related', 'tools', 'cold', 'missing_people', 'earthquake', 'money', 'shelter', 'fire', 'infrastructure_related', 'other_infrastructure', 'security', 'request', 'weather_related', 'medical_products', 'refugees', 'other_aid', 'death', 'transport']\n"
     ]
    }
   ],
   "source": [
    "database_filepath = 'data/DisasterResponse.db'\n",
    "model_filepath = 'models/clasisfier3.pkl'\n",
    "print('Loading data...\\n    DATABASE: {}'.format(database_filepath))\n",
    "X, Y, category_names = load_data(database_filepath)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n"
     ]
    }
   ],
   "source": [
    "print('Building model...')\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__estimator__min_samples_split=8 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:451: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:451: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=8, score=0.4961378476499129, total= 2.6min\n",
      "[CV] clf__estimator__min_samples_split=8 ............................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:451: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:451: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  5.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=8, score=0.4929992408288853, total= 2.0min\n",
      "[CV] clf__estimator__min_samples_split=8 ............................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:451: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:451: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV]  clf__estimator__min_samples_split=8, score=0.49172140606020626, total= 2.0min\n",
      "[CV] clf__estimator__min_samples_split=16 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:451: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:451: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=16, score=0.4960727136651752, total= 1.9min\n",
      "[CV] clf__estimator__min_samples_split=16 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:451: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:451: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=16, score=0.4940717577506172, total= 1.9min\n",
      "[CV] clf__estimator__min_samples_split=16 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:451: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:451: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 15.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=16, score=0.4883931812596443, total= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:451: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buildings\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      9924\n",
      "           1       0.83      0.15      0.26       563\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10487\n",
      "   macro avg       0.89      0.57      0.62     10487\n",
      "weighted avg       0.95      0.95      0.94     10487\n",
      "\n",
      "f1 score: 0.9369736709983834\n",
      "other_weather\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      9911\n",
      "           1       0.51      0.03      0.07       576\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10487\n",
      "   macro avg       0.73      0.52      0.52     10487\n",
      "weighted avg       0.92      0.95      0.92     10487\n",
      "\n",
      "f1 score: 0.9219554372267377\n",
      "search_and_rescue\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     10196\n",
      "           1       0.65      0.10      0.18       291\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     10487\n",
      "   macro avg       0.81      0.55      0.58     10487\n",
      "weighted avg       0.97      0.97      0.96     10487\n",
      "\n",
      "f1 score: 0.964141732095381\n",
      "floods\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      9625\n",
      "           1       0.91      0.53      0.67       862\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10487\n",
      "   macro avg       0.93      0.76      0.82     10487\n",
      "weighted avg       0.96      0.96      0.95     10487\n",
      "\n",
      "f1 score: 0.9514428337176088\n",
      "clothing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     10342\n",
      "           1       0.69      0.29      0.41       145\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     10487\n",
      "   macro avg       0.84      0.64      0.70     10487\n",
      "weighted avg       0.99      0.99      0.99     10487\n",
      "\n",
      "f1 score: 0.9860182072398329\n",
      "hospitals\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     10386\n",
      "           1       0.00      0.00      0.00       101\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     10487\n",
      "   macro avg       0.50      0.50      0.50     10487\n",
      "weighted avg       0.98      0.99      0.99     10487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\kempbri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "f1 score: 0.9855768435912041\n",
      "water\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      9853\n",
      "           1       0.80      0.59      0.68       634\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     10487\n",
      "   macro avg       0.89      0.79      0.83     10487\n",
      "weighted avg       0.96      0.97      0.96     10487\n",
      "\n",
      "f1 score: 0.9638424841098511\n",
      "food\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      9344\n",
      "           1       0.81      0.71      0.76      1143\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10487\n",
      "   macro avg       0.89      0.85      0.87     10487\n",
      "weighted avg       0.95      0.95      0.95     10487\n",
      "\n",
      "f1 score: 0.949526828907321\n",
      "shops\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     10442\n",
      "           1       0.00      0.00      0.00        45\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     10487\n",
      "   macro avg       0.50      0.50      0.50     10487\n",
      "weighted avg       0.99      1.00      0.99     10487\n",
      "\n",
      "f1 score: 0.9935680726469837\n",
      "medical_help\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96      9705\n",
      "           1       0.63      0.14      0.24       782\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10487\n",
      "   macro avg       0.78      0.57      0.60     10487\n",
      "weighted avg       0.91      0.93      0.91     10487\n",
      "\n",
      "f1 score: 0.9090465796109851\n",
      "aid_centers\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     10350\n",
      "           1       0.00      0.00      0.00       137\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     10487\n",
      "   macro avg       0.49      0.50      0.50     10487\n",
      "weighted avg       0.97      0.99      0.98     10487\n",
      "\n",
      "f1 score: 0.9804472562919515\n",
      "storm\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      9492\n",
      "           1       0.78      0.64      0.70       995\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10487\n",
      "   macro avg       0.87      0.81      0.84     10487\n",
      "weighted avg       0.95      0.95      0.95     10487\n",
      "\n",
      "f1 score: 0.9464165918683674\n",
      "direct_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92      8494\n",
      "           1       0.81      0.36      0.50      1993\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10487\n",
      "   macro avg       0.84      0.67      0.71     10487\n",
      "weighted avg       0.86      0.86      0.84     10487\n",
      "\n",
      "f1 score: 0.8400157208637492\n",
      "offer\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     10439\n",
      "           1       0.00      0.00      0.00        48\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     10487\n",
      "   macro avg       0.50      0.50      0.50     10487\n",
      "weighted avg       0.99      1.00      0.99     10487\n",
      "\n",
      "f1 score: 0.9931396062870756\n",
      "military\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     10110\n",
      "           1       0.67      0.08      0.15       377\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     10487\n",
      "   macro avg       0.82      0.54      0.56     10487\n",
      "weighted avg       0.96      0.97      0.95     10487\n",
      "\n",
      "f1 score: 0.9523853213833685\n",
      "electricity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     10288\n",
      "           1       0.74      0.13      0.22       199\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     10487\n",
      "   macro avg       0.86      0.56      0.61     10487\n",
      "weighted avg       0.98      0.98      0.98     10487\n",
      "\n",
      "f1 score: 0.9766321920397972\n",
      "aid_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81      6099\n",
      "           1       0.75      0.67      0.71      4388\n",
      "\n",
      "   micro avg       0.77      0.77      0.77     10487\n",
      "   macro avg       0.76      0.75      0.76     10487\n",
      "weighted avg       0.77      0.77      0.76     10487\n",
      "\n",
      "f1 score: 0.7645768950389077\n",
      "tools\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     10431\n",
      "           1       0.00      0.00      0.00        56\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     10487\n",
      "   macro avg       0.50      0.50      0.50     10487\n",
      "weighted avg       0.99      0.99      0.99     10487\n",
      "\n",
      "f1 score: 0.991997230796714\n",
      "cold\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     10274\n",
      "           1       0.72      0.16      0.26       213\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     10487\n",
      "   macro avg       0.85      0.58      0.63     10487\n",
      "weighted avg       0.98      0.98      0.98     10487\n",
      "\n",
      "f1 score: 0.9759203801904394\n",
      "missing_people\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     10367\n",
      "           1       0.67      0.02      0.03       120\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     10487\n",
      "   macro avg       0.83      0.51      0.51     10487\n",
      "weighted avg       0.99      0.99      0.98     10487\n",
      "\n",
      "f1 score: 0.9832875281685498\n",
      "earthquake\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      9515\n",
      "           1       0.88      0.76      0.82       972\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     10487\n",
      "   macro avg       0.93      0.88      0.90     10487\n",
      "weighted avg       0.97      0.97      0.97     10487\n",
      "\n",
      "f1 score: 0.9676916864754606\n",
      "money\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     10228\n",
      "           1       0.92      0.05      0.09       259\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     10487\n",
      "   macro avg       0.95      0.52      0.54     10487\n",
      "weighted avg       0.98      0.98      0.97     10487\n",
      "\n",
      "f1 score: 0.9657982666157698\n",
      "shelter\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      9563\n",
      "           1       0.78      0.53      0.63       924\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10487\n",
      "   macro avg       0.87      0.76      0.80     10487\n",
      "weighted avg       0.94      0.95      0.94     10487\n",
      "\n",
      "f1 score: 0.9406705803999602\n",
      "fire\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     10373\n",
      "           1       0.73      0.07      0.13       114\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     10487\n",
      "   macro avg       0.86      0.53      0.56     10487\n",
      "weighted avg       0.99      0.99      0.99     10487\n",
      "\n",
      "f1 score: 0.9853495990776545\n",
      "infrastructure_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97      9787\n",
      "           1       0.00      0.00      0.00       700\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10487\n",
      "   macro avg       0.47      0.50      0.48     10487\n",
      "weighted avg       0.87      0.93      0.90     10487\n",
      "\n",
      "f1 score: 0.9010283630331964\n",
      "other_infrastructure\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98     10002\n",
      "           1       0.00      0.00      0.00       485\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10487\n",
      "   macro avg       0.48      0.50      0.49     10487\n",
      "weighted avg       0.91      0.95      0.93     10487\n",
      "\n",
      "f1 score: 0.9311757676427631\n",
      "security\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     10285\n",
      "           1       0.00      0.00      0.00       202\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     10487\n",
      "   macro avg       0.49      0.50      0.50     10487\n",
      "weighted avg       0.96      0.98      0.97     10487\n",
      "\n",
      "f1 score: 0.9712007425917972\n",
      "request\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94      8723\n",
      "           1       0.86      0.46      0.60      1764\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     10487\n",
      "   macro avg       0.88      0.72      0.77     10487\n",
      "weighted avg       0.89      0.90      0.88     10487\n",
      "\n",
      "f1 score: 0.8841257719419315\n",
      "weather_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92      7542\n",
      "           1       0.85      0.70      0.77      2945\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10487\n",
      "   macro avg       0.87      0.83      0.84     10487\n",
      "weighted avg       0.88      0.88      0.88     10487\n",
      "\n",
      "f1 score: 0.8778176966433274\n",
      "medical_products\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     10014\n",
      "           1       0.76      0.21      0.33       473\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10487\n",
      "   macro avg       0.86      0.60      0.66     10487\n",
      "weighted avg       0.95      0.96      0.95     10487\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.9508204171281999\n",
      "refugees\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     10150\n",
      "           1       0.68      0.08      0.14       337\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     10487\n",
      "   macro avg       0.82      0.54      0.56     10487\n",
      "weighted avg       0.96      0.97      0.96     10487\n",
      "\n",
      "f1 score: 0.9572899130827973\n",
      "other_aid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93      9120\n",
      "           1       0.60      0.04      0.07      1367\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10487\n",
      "   macro avg       0.73      0.52      0.50     10487\n",
      "weighted avg       0.84      0.87      0.82     10487\n",
      "\n",
      "f1 score: 0.8184516987751452\n",
      "death\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     10021\n",
      "           1       0.80      0.38      0.51       466\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     10487\n",
      "   macro avg       0.88      0.69      0.75     10487\n",
      "weighted avg       0.96      0.97      0.96     10487\n",
      "\n",
      "f1 score: 0.9624098568024099\n",
      "transport\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     10029\n",
      "           1       0.79      0.14      0.24       458\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10487\n",
      "   macro avg       0.87      0.57      0.61     10487\n",
      "weighted avg       0.95      0.96      0.95     10487\n",
      "\n",
      "f1 score: 0.9477729457963282\n",
      "Saving model...\n",
      "    MODEL: models/clasisfier3.pkl\n",
      "Trained model saved!\n"
     ]
    }
   ],
   "source": [
    "print('Training model...')\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "print('Evaluating model...')\n",
    "evaluate_model(model, X_test, Y_test)\n",
    "# Note: used to also include parameter category_names\n",
    "\n",
    "print('Saving model...\\n    MODEL: {}'.format(model_filepath))\n",
    "save_model(model, model_filepath)\n",
    "\n",
    "print('Trained model saved!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <function tokenize at 0x0000018ED7D4B268>: it's not the same object as __main__.tokenize",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-eb7521b3c7c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# load model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_filepath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mPicklingError\u001b[0m: Can't pickle <function tokenize at 0x0000018ED7D4B268>: it's not the same object as __main__.tokenize"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "pickle.dump(model2, open(model_filepath,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
